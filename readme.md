# 斯坦福大学机器学习训练营(Andrew Ng)


## 课程资料
1. [课程主页](https://www.coursera.org/course/ml)  
2. [课程笔记](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%AE%8C%E6%95%B4%E7%89%88%EF%BC%89.pdf)  
3. [课程视频](https://www.bilibili.com/video/av9912938/?p=1)  
4. [环境配置Anaconda](https://github.com/learning511/Stanford-Machine-Learning-camp/tree/master)
5. [作业介绍](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/%E4%BD%9C%E4%B8%9A.md) 
6. 比赛环境推荐使用Linux或者Mac系统，以下环境搭建方法皆适用:  
    [Docker环境配置](https://github.com/ufoym/deepo)  
    [本地环境配置](https://github.com/learning511/cs224n-learning-camp/blob/master/environment.md)


## 重要一些的资源：
1. [深度学习经典论文](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap.git)
2. [深度学习斯坦福教程](http://deeplearning.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B)
3. [廖雪峰python3教程](https://www.liaoxuefeng.com/article/001432619295115c918a094d8954bd493037b03d27bf9a9000)
4. [github教程](https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000)
5. [莫烦机器学习教程](https://morvanzhou.github.io/tutorials)
6. [深度学习经典论文](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap.git)
7. [机器学习代码修行100天](https://github.com/Avik-Jain/100-Days-Of-ML-Code)  
8. [吴恩达机器学习新书：machine learning yearning](https://github.com/AcceptedDoge/machine-learning-yearning-cn)  
9. [本人博客(机器学习基础算法专题)](https://blog.csdn.net/dukuku5038/article/details/82253966)  
10. [本人博客(深度学习专题)](https://blog.csdn.net/column/details/28693.html)  
11. [自上而下的学习路线: 软件工程师的机器学习](https://github.com/ZuzooVn/machine-learning-for-software-engineers/blob/master/README-zh-CN.md)  



## 1. 前言 
### 这门课的宗旨就是：**“手把手推导机器学习理论，行对行练习徒手代码过程” ** 

吴恩达在斯坦福的机器学习课，是很多人最初入门机器学习的课，10年有余，目前仍然是最经典的机器学习课程之一。当时因为这门课太火爆，吴恩达不得不弄了个超大的网络课程来授课，结果一不小心从斯坦福火遍全球，而后来的事情大家都知道了。吴恩达这些年，从谷歌大脑项目到创立Coursera再到百度首席科学家再再到最新开设了深度学习deeplearning.ai，辗转多年依然对CS229不离不弃。  

个人认为：吴恩达的机器学习课程在机器学习入门的贡献相当于牛顿、莱布尼茨对于微积分的贡献。区别在于，吴恩达影响了10年，牛顿影响了200年。(个人观点)

本课程提供了一个广泛的介绍机器学习、数据挖掘、统计模式识别的课程。主题包括：

（一）监督学习（参数/非参数算法，支持向量机，核函数，神经网络）。

（二）无监督学习（聚类，降维，推荐系统，深入学习推荐）。

（三）在机器学习的最佳实践（偏差/方差理论；在机器学习和人工智能创新过程）。本课程还将使用大量的案例研究，您还将学习如何运用学习算法构建智能机器人（感知，控制），文本的理解（Web搜索，反垃圾邮件），计算机视觉，医疗信息，音频，数据挖掘，和其他领域。

本课程相对以前的机器学习视频cs229(2008)，这个视频更加清晰，而且每课都有课件，推荐学习。

## 2.数学知识复习  
1.[线性代数](http://web.stanford.edu/class/cs224n/readings/cs229-linalg.pdf)  
2.[概率论](http://web.stanford.edu/class/cs224n/readings/cs229-prob.pdf)  
3.[凸函数优化](http://web.stanford.edu/class/cs224n/readings/cs229-cvxopt.pdf)  
4.[随机梯度下降算法](http://cs231n.github.io/optimization-1/)  

#### 中文资料：    
- [机器学习中的数学基本知识](https://www.cnblogs.com/steven-yang/p/6348112.html)  
- [统计学习方法](http://vdisk.weibo.com/s/vfFpMc1YgPOr)  
**大学数学课本（从故纸堆里翻出来^_^）**  

### 3.编程工具 
#### 斯坦福资料： 
- [Python复习](http://web.stanford.edu/class/cs224n/lectures/python-review.pdf)  

#### 4. 中文书籍推荐：
- 《机器学习》周志华  

- 《统计学习方法》李航  

- 《机器学习课》邹博  

## 5. 学习安排
本课程需要11周共18节课，
每周具体时间划分为4个部分:  
- 1部分安排周一到周二  
- 2部分安排在周四到周五  
- 3部分安排在周日  
- 4部分作业是本周任何时候空余时间    
- 周日晚上提交作业运行截图  
- 周三、周六休息^_^  

#### 6.作业提交指南：  
 训练营的作业自检系统已经正式上线啦！只需将作业发送到训练营公共邮箱即可，知识星球以打卡为主，不用提交作业。以下为注意事项:  
<1> 训练营代码公共邮箱：cs229@163.com  
<2> [查询自己成绩:](https://shimo.im/sheets/HUCGWzMQGu8iCqT1)  
<3> 将每周作业压缩成zip文件，文件名为“学号+作业编号”，例如："CS229-010037-01.zip"  
<4> 注意不要改变作业中的《方法名》《类名》不然会检测失败！！ 

## 7.学习安排
### week 1  
**学习组队**  
**比赛观摩**  

**作业 Week1：**:  
制定自己的学习计划  

### week 2 
**第一节： 引言(Introduction)**  
**课件：**[lecture1](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture1.pdf)  
**笔记：**[lecture1-note1](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture1.pdf)  
**视频：**  
	1.1欢迎:[Welcome to Machine Learning](https://www.bilibili.com/video/av9912938/?p=1)  
	1.2机器学习是什么？:[Welcome](https://www.bilibili.com/video/av9912938/?p=2)  
	1.3监督学习:[What is Machine Learning](https://www.bilibili.com/video/av9912938/?p=3)  
	1.4无监督学习:[Supervised Learning](https://www.bilibili.com/video/av9912938/?p=4)  

**第二节： 单变量线性回归(Linear Regression with One Variable)**  
**课件：**[lecture2](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture2.pdf)  
**笔记：**[lecture2-note2](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture2.pdf)  
**视频：**    
		2.1模型表示:[Unsupervised Learning](https://www.bilibili.com/video/av9912938/?p=5)  
		2.2代价函数:[Model Representation](https://www.bilibili.com/video/av9912938/?p=6)  
		2.3代价函数的直观理解I:[Cost Function](https://www.bilibili.com/video/av9912938/?p=7)  
		2.4代价函数的直观理解II:[Cost Function - Intuition I](https://www.bilibili.com/video/av9912938/?p=8)  
		2.5梯度下降:[Cost Function - Intuition II](https://www.bilibili.com/video/av9912938/?p=9)  
		2.6梯度下降的直观理解:[Gradient Descent](https://www.bilibili.com/video/av9912938/?p=10)  
		2.7梯度下降的线性回归:[Gradient Descent Intuition](https://www.bilibili.com/video/av9912938/?p=11)  
		2.8接下来的内容:[GradientDescentForLinearRegression](https://www.bilibili.com/video/av9912938/?p=12)                                     

**作业 Week2：**:  
1.环境配置  
2.开学习博客和github  

---------------------------------------------------------
### week 3   
**第三节： 线性代数回顾(Linear Algebra Review)**  
**课件：**[lecture3](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture3.pdf)  
**笔记：**[lecture3-note3](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture3.pdf)  
**视频：**  
	3.1矩阵和向量:[Matrices and Vectors](https://www.bilibili.com/video/av9912938/?p=13)  
	3.2加法和标量乘法:[Addition and Scalar Multiplication](https://www.bilibili.com/video/av9912938/?p=14)  
	3.3矩阵向量乘法:[Matrix Vector Multiplication](https://www.bilibili.com/video/av9912938/?p=15)  
	3.4矩阵乘法:[Matrix Matrix Multiplication](https://www.bilibili.com/video/av9912938/?p=16)  
	3.5矩阵乘法的性质:[Matrix Multiplication Properties](https://www.bilibili.com/video/av9912938/?p=17)  
	3.6逆、转置:[Inverse and Transpose](https://www.bilibili.com/video/av9912938/?p=18)  
	
**第四节： 多变量线性回归(Linear Regression with Multiple Variables)**  
**课件：**[lecture4](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture4.pdf)  
**笔记：**[lecture4-note4](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture4.pdf)  
**视频：**  
	4.1多维特征:[Multiple Features](https://www.bilibili.com/video/av9912938/?p=19)  
	4.2多变量梯度下降:[Gradient Descent for Multiple Variables](https://www.bilibili.com/video/av9912938/?p=20)  
	4.3梯度下降法实践1-特征缩放:[Gradient Descent in Practice I - Feature Scaling](https://www.bilibili.com/video/av9912938/?p=21)  
	4.4梯度下降法实践2-学习率:[Gradient Descent in Practice II - Learning Rate](https://www.bilibili.com/video/av9912938/?p=22)  
	4.5特征和多项式回归:[Features and Polynomial Regression](https://www.bilibili.com/video/av9912938/?p=23)  
	4.6正规方程:[Normal Equation](https://www.bilibili.com/video/av9912938/?p=24)  
	4.7正规方程及不可逆性（选修）:[Normal Equation Noninvertibility (Optional)](https://www.bilibili.com/video/av9912938/?p=25)  
**作业 Week3：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex1/ex1.pdf)  
1.线性回归 Linear Regression  
2.多远线性回归 Linear Regression with multiple variables

---------------------------------------------------------

### Week 4  
**第五节：Octave教程(Octave Tutorial 选修)（有Python基础可以忽略）**  
**课件：**[lecture5](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture5.pdf)  
**笔记：**[lecture5-note5](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture5.pdf)  
**视频：**  
	5.1基本操作:[Working on and Submitting Programming Exercises](https://www.bilibili.com/video/av9912938/?p=26)  
	5.2移动数据:[Basic Operations](https://www.bilibili.com/video/av9912938/?p=27)  
	5.3计算数据:[Moving Data Around](https://www.bilibili.com/video/av9912938/?p=28)  
	5.4绘图数据:[Computing on Data](https://www.bilibili.com/video/av9912938/?p=29)  
	5.5控制语句：for，while，if语句:[Plotting Data](https://www.bilibili.com/video/av9912938/?p=30)  
	5.6向量化88:[Control Statements](https://www.bilibili.com/video/av9912938/?p=31)  
	5.7工作和提交的编程练习:[Vectorization](https://www.bilibili.com/video/av9912938/?p=32)  

**第六节：逻辑回归(Logistic Regression)**  
**课件：**[lecture6](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture6.pdf)  
**笔记：**[lecture6-note6](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture6.pdf)  
**视频：**  
	6.1分类问题:[Classification](https://www.bilibili.com/video/av9912938/?p=33)  
	6.2假说表示:[Hypothesis Representation](https://www.bilibili.com/video/av9912938/?p=34)  
	6.3判定边界:[Decision Boundary](https://www.bilibili.com/video/av9912938/?p=35)  
	6.4代价函数:[Cost Function](https://www.bilibili.com/video/av9912938/?p=36)  
	6.5简化的成本函数和梯度下降:[Simplified Cost Function and Gradient Descent](https://www.bilibili.com/video/av9912938/?p=37)  
	6.6高级优化:[Advanced Optimization](https://www.bilibili.com/video/av9912938/?p=38)  
	6.7多类别分类：一对多:[Multiclass Classification_ One-vs-all](https://www.bilibili.com/video/av9912938/?p=39)  

**作业 Week4：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex2/ex2.pdf)  
1. 逻辑回归 Logistic Regression
2. 带有正则项的逻辑回归 Logistic Regression with Regularization

---------------------------------------------------------

### Week 5     
**第七节：正则化(Regularization)**  
**课件：**[lecture7](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture7.pdf)  
**笔记：**[lecture7-note7](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture7.pdf)  
**视频：**                                  
	7.1过拟合的问题:[The Problem of Overfitting](https://www.bilibili.com/video/av9912938/?p=40)  
	7.2代价函数:[Cost Function](https://www.bilibili.com/video/av9912938/?p=41)  
	7.3正则化线性回归:[Regularized Linear Regression](https://www.bilibili.com/video/av9912938/?p=42)  
	7.4正则化的逻辑回归模型:[Regularized Logistic Regression](https://www.bilibili.com/video/av9912938/?p=43)  

**第八节：神经网络：表述(Neural Networks: Representation)**  
**课件：**[lecture8](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture8.pdf)  
**笔记：**[lecture8-note8](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture8.pdf)  
**视频：**   
	8.1非线性假设:[Non-linear Hypotheses](https://www.bilibili.com/video/av9912938/?p=44)  
	8.2神经元和大脑:[Neurons and the Brain](https://www.bilibili.com/video/av9912938/?p=45)  
	8.3模型表示1:[Model Representation I](https://www.bilibili.com/video/av9912938/?p=46)  
	8.4模型表示2:[Model Representation II](https://www.bilibili.com/video/av9912938/?p=47)  
	8.5样本和直观理解1:[Examples and Intuitions I](https://www.bilibili.com/video/av9912938/?p=48)  
	8.6样本和直观理解II:[Examples and Intuitions II](https://www.bilibili.com/video/av9912938/?p=49)  
	8.7多类分类:[Multiclass Classification](https://www.bilibili.com/video/av9912938/?p=50)  
**作业 Week5：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex3/ex3.pdf)  
1. 多元分类 Multiclass Classification
2. 神经网络预测函数 Neural Networks Prediction fuction

---------------------------------------------------------
   

### Week 6  
**第九节1：神经网络的学习(Neural Networks: Learning1)**  
**课件：**[lecture9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture9.pdf)  
**笔记：**[lecture9-note9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture9.pdf)   
**视频：**   
	9.1代价函数:[Cost Function](https://www.bilibili.com/video/av9912938/?p=51)  
	9.2反向传播算法:[Backpropagation Algorithm](https://www.bilibili.com/video/av9912938/?p=52)  
	9.3反向传播算法的直观理解:[Backpropagation Intuition](https://www.bilibili.com/video/av9912938/?p=53)  

**第九节2：神经网络的学习(Neural Networks: Learning2)**  
**课件：**[lecture9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture9.pdf)  
**笔记：**[lecture9-note9](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture9.pdf)  
**视频：**   
	9.4实现注意：展开参数:[Implementation Note_ Unrolling Parameters](https://www.bilibili.com/video/av9912938/?p=54)  
	9.5梯度检验:[Gradient Checking](https://www.bilibili.com/video/av9912938/?p=55)  
	9.6随机初始化:[Random Initialization](https://www.bilibili.com/video/av9912938/?p=56)  
	9.7综合起来:[Putting It Together](https://www.bilibili.com/video/av9912938/?p=57)  
	9.8自主驾驶:[Autonomous Driving](https://www.bilibili.com/video/av9912938/?p=58)  

**作业 Week6：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex4/ex4.pdf)  
1. 神经网络实现 Neural Networks Learning  

---------------------------------------------------------

### Week 7  
**第十节：应用机器学习的建议(Advice for Applying Machine Learning)**  
**课件：**[lecture10](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture10.pdf)  
**笔记：**[lecture10-note10](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture10.pdf)  
**视频：**  
	10.1决定下一步做什么:[Deciding What to Try Next](https://www.bilibili.com/video/av9912938/?p=59)  
	10.2评估一个假设:[Evaluating a Hypothesis](https://www.bilibili.com/video/av9912938/?p=60)  
	10.3模型选择和交叉验证集:[Model Selection and Train_Validation_Test Sets](https://www.bilibili.com/video/av9912938/?p=61)  
	10.4诊断偏差和方差:[Diagnosing Bias vs. Variance](https://www.bilibili.com/video/av9912938/?p=62)  
	10.5正则化和偏差/方差:[Regularization and Bias_Variance](https://www.bilibili.com/video/av9912938/?p=63)  
	10.6学习曲线:[Learning Curves](https://www.bilibili.com/video/av9912938/?p=64)  
	10.7决定下一步做什么:[Deciding What to Do Next Revisited](https://www.bilibili.com/video/av9912938/?p=65)                                        
**第十一节：  机器学习系统的设计(Machine Learning System Design)**  
**课件：**[lecture11](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture11.pdf)  
**笔记：**[lecture11-note11](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture11.pdf)  
**视频：**  
	11.1首先要做什么:[Prioritizing What to Work On](https://www.bilibili.com/video/av9912938/?p=66)  
	11.2误差分析:[Error Analysis](https://www.bilibili.com/video/av9912938/?p=67)  
	11.3类偏斜的误差度量:[Error Metrics for Skewed Classes](https://www.bilibili.com/video/av9912938/?p=68)  
	11.4查准率和查全率之间的权衡:[Trading Off Precision and Recall](https://www.bilibili.com/video/av9912938/?p=69)  
	11.5机器学习的数据:[Data For Machine Learning](https://www.bilibili.com/video/av9912938/?p=70)  
**作业 Week7：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex5/ex5.pdf)  
1. 正则线性回归 Regularized Linear Regression  
2. 偏移和方差 Bias vs. Variance  

---------------------------------------------------------

### Week 8  
**第十二节：支持向量机(Support Vector Machines)**  
**课件：**[lecture12](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture12.pdf)  
**笔记：**[lecture12-note12](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture12.pdf)  
**视频：**  
	12.1优化目标:[Optimization Objective](https://www.bilibili.com/video/av9912938/?p=71)  
	12.2大边界的直观理解:[Large Margin Intuition](https://www.bilibili.com/video/av9912938/?p=72)  
	12.3数学背后的大边界分类（选修）:[Mathematics Behind Large Margin Classification (Optional)](https://www.bilibili.com/video/av9912938/?p=73)  
	12.4核函数1:[Kernels I](https://www.bilibili.com/video/av9912938/?p=74)  
	12.5核函数2:[Kernels II](https://www.bilibili.com/video/av9912938/?p=75)  
	12.6使用支持向量机:[Using An SVM](https://www.bilibili.com/video/av9912938/?p=76)  

**第十三节：聚类(Clustering)**  
**课件：**[lecture13](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture13.pdf)  
**笔记：**[lecture13-note13](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture13.pdf)  
**视频：**   
	13.1无监督学习：简介:[Unsupervised Learning_ Introduction](https://www.bilibili.com/video/av9912938/?p=77)  
	13.2K-均值算法:[K-Means Algorithm](https://www.bilibili.com/video/av9912938/?p=78)  
	13.3优化目标:[Optimization Objective](https://www.bilibili.com/video/av9912938/?p=79)  
	13.4随机初始化:[Random Initialization](https://www.bilibili.com/video/av9912938/?p=80)  
	13.5选择聚类数:[Choosing the Number of Clusters](https://www.bilibili.com/video/av9912938/?p=81)  
**作业 Week8：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex6/ex6.pdf)  
1. SVM实现
2. 垃圾邮件分类 Spam email Classifier  

---------------------------------------------------------

### Week 9
**第十四节：降维(Dimensionality Reduction)**  
**课件：**[lecture14](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture14.pdf)  
**笔记：**[lecture14-note14](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture14.pdf)  
**视频：**     
	14.1动机一：数据压缩:[Motivation I_ Data Compression](https://www.bilibili.com/video/av9912938/?p=82)  
	14.2动机二：数据可视化:[Motivation II_ Visualization](https://www.bilibili.com/video/av9912938/?p=83)  
	14.3主成分分析问题:[Principal Component Analysis Problem Formulation](https://www.bilibili.com/video/av9912938/?p=84)  
	14.4主成分分析算法:[Principal Component Analysis Algorithm](https://www.bilibili.com/video/av9912938/?p=85)  
	14.5选择主成分的数量:[Choosing the Number of Principal Components](https://www.bilibili.com/video/av9912938/?p=86)  
	14.6重建的压缩表示:[Reconstruction from Compressed Representation](https://www.bilibili.com/video/av9912938/?p=87)  
	14.7主成分分析法的应用建议:[Advice for Applying PCA](https://www.bilibili.com/video/av9912938/?p=88)  

**第十五节：异常检测(Anomaly Detection)**  
**课件：**[lecture15](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture15.pdf)  
**笔记：**[lecture15-note15](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture15.pdf)  
**视频：**   
	15.1问题的动机:[Problem Motivation](https://www.bilibili.com/video/av9912938/?p=89)  
	15.2高斯分布:[Gaussian Distribution](https://www.bilibili.com/video/av9912938/?p=90)  
	15.3算法:[Algorithm](https://www.bilibili.com/video/av9912938/?p=91)  
	15.4开发和评价一个异常检测系统:[Developing and Evaluating an Anomaly Detection System](https://www.bilibili.com/video/av9912938/?p=92)  
	15.5异常检测与监督学习对比:[Anomaly Detection vs. Supervised Learning](https://www.bilibili.com/video/av9912938/?p=93)  
	15.6选择特征:[Choosing What Features to Use](https://www.bilibili.com/video/av9912938/?p=94)  
	15.7多元高斯分布（选修）:[Multivariate Gaussian Distribution (Optional)](https://www.bilibili.com/video/av9912938/?p=95)  
	15.8使用多元高斯分布进行异常检测（选修）:[Anomaly Detection using the Multivariate Gaussian Distribution (Optiona](https://www.bilibili.com/video/av9912938/?p=96)  
**作业 Week9：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex7/ex7.pdf)  
1. K-means 聚类算法 Clustering  
2. PCA 主成分析 Principal Component Analysis  

---------------------------------------------------------


### Week 10  
**第十六节：推荐系统(Recommender Systems)**  
**课件：**[lecture16](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture16.pdf)  
**笔记：**[lecture16-note16](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture16.pdf)  
**视频：**  
	16.1问题形式化:[Problem Formulation](https://www.bilibili.com/video/av9912938/?p=97)  
	16.2基于内容的推荐系统:[Content Based Recommendations](https://www.bilibili.com/video/av9912938/?p=98)  
	16.3协同过滤:[Collaborative Filtering](https://www.bilibili.com/video/av9912938/?p=99)  
	16.4协同过滤算法:[Collaborative Filtering Algorithm](https://www.bilibili.com/video/av9912938/?p=100)  
	16.5向量化：低秩矩阵分解:[Vectorization_ Low Rank Matrix Factorization](https://www.bilibili.com/video/av9912938/?p=101)  
	16.6推行工作上的细节：均值归一化:[Implementational Detail_ Mean Normalization](https://www.bilibili.com/video/av9912938/?p=102)  

**第十七节：大规模机器学习(Large Scale Machine Learning)**  
**课件：**[lecture17](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture17.pdf)  
**笔记：**[lecture17-note17](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture17.pdf))  
**视频：**  
	17.1大型数据集的学习:[Learning With Large Datasets](https://www.bilibili.com/video/av9912938/?p=103)  
	17.2随机梯度下降法:[Stochastic Gradient Descent](https://www.bilibili.com/video/av9912938/?p=104)  
	17.3小批量梯度下降:[Mini-Batch Gradient Descent](https://www.bilibili.com/video/av9912938/?p=105)  
	17.4随机梯度下降收敛:[Stochastic Gradient Descent Convergence](https://www.bilibili.com/video/av9912938/?p=106)  
	17.5在线学习:[Online Learning](https://www.bilibili.com/video/av9912938/?p=107)  
	17.6映射化简和数据并行:[Map Reduce and Data Parallelism](https://www.bilibili.com/video/av9912938/?p=108)  

**作业 Week10：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex8/ex8.pdf)  
  
1. 异常检测 Anomaly Detection    

---------------------------------------------------------


### Week 11  
**第十八节1： 应用实例：图片文字识别(Application Example: Photo OCR)**  
**课件：**[lecture18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture18.pdf)  
**笔记：**[lecture18-note18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture18.pdf)  
**视频：**  
	18.1问题描述和流程图:[Problem Description and Pipeline](https://www.bilibili.com/video/av9912938/?p=109)  
	18.2滑动窗口:[Sliding Windows](https://www.bilibili.com/video/av9912938/?p=110)   
**第十八节2： 应用实例：图片文字识别(Application Example: Photo OCR)**  
**课件：**[lecture18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture%20/Lecture18.pdf)  
**笔记：**[lecture1-note18](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Course/lecture-notes/lecture18.pdf))  
**视频：**   
	18.3获取大量数据和人工数据:[Getting Lots of Data and Artificial Data](https://www.bilibili.com/video/av9912938/?p=111)  
	18.4上限分析：哪部分管道的接下去做:[Ceiling Analysis_ What Part of the Pipeline to Work on Next](https://www.bilibili.com/video/av9912938/?p=112)  


**作业 Week11：**: [作业链接](https://github.com/learning511/Stanford-Machine-Learning-camp/blob/master/Assignments/machine-learning-ex8/ex8.pdf)  
2.推荐系统实现 Recommender Systems  
**课程比赛：比赛介绍: **  

---------------------------------------------------------

### Week 12
**第十九节：总结(Conclusion)**  
**视频：**  
19.1总结和致谢:[Summary and Thank You](https://www.bilibili.com/video/av9912938/?p=113)  
**课程比赛：比赛: **  
 Kaggle 比赛： 泰坦尼克 Titanic
 
 ---------------------------------------------------------
